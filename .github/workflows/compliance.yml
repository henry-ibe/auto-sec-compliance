name: Compliance (main)

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      instance_id:
        description: "EC2 InstanceId (optional; falls back to first SSM Online Linux)"
        required: false
        default: ""

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  BUCKET:     ${{ vars.BUCKET }}
  ROLE_ARN:   ${{ vars.AWS_ROLE_ARN }}
  PHASE:      ci

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Ensure jq (runner)
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Configure AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.ROLE_ARN }}
          aws-region:     ${{ env.AWS_REGION }}

      - name: Resolve target instance (SSM Online or provided)
        id: target
        shell: bash
        run: |
          set -euo pipefail
          IID="${{ github.event.inputs.instance_id || '' }}"
          if [ -z "$IID" ]; then IID="${{ vars.INSTANCE_ID || '' }}"; fi
          if [ -z "$IID" ]; then
            IID=$(aws ssm describe-instance-information \
              --filters "Key=PingStatus,Values=Online" "Key=PlatformType,Values=Linux" \
              --query 'InstanceInformationList[0].InstanceId' --output text || true)
          fi
          if [ -z "$IID" ] || [ "$IID" = "None" ]; then
            echo "No SSM Online instance found. Set repo var INSTANCE_ID or pass the input." >&2
            exit 1
          fi
          echo "iid=$IID" >> "$GITHUB_OUTPUT"

      - name: Build remote script and stage to S3 (avoid 8KB SSM limit)
        id: stage
        shell: bash
        env:
          BUCKET: ${{ env.BUCKET }}
          REGION: ${{ env.AWS_REGION }}
          PHASE:  ${{ env.PHASE }}
        run: |
          set -euo pipefail
          RUN=$(date -u +%Y%m%dT%H%M%SZ)
          echo "run=$RUN" >> "$GITHUB_OUTPUT"

          cat > remote.sh <<'EOS'
          #!/usr/bin/env bash
          set -euo pipefail
          export PATH="$HOME/.local/bin:$PATH"

          BUCKET="${BUCKET}"
          REGION="${REGION}"
          PHASE="${PHASE}"
          RUN="${RUN}"

          sudo dnf -y install lynis openscap openscap-scanner scap-security-guide jq python3 || \
          sudo yum -y install lynis openscap openscap-scanner scap-security-guide jq python3 || true

          sudo dnf -y install ansible-core || sudo yum -y install ansible-core || \
            python3 -m pip install --user --upgrade ansible

          cat >/tmp/pb.yml <<'PYAML'
          - name: Baseline + Scan + Collect
            hosts: localhost
            connection: local
            become: true
            gather_facts: true
            vars: { reports_dir: /tmp/reports }
            tasks:
              - name: Ensure reports dir exists
                file: { path: "{{ reports_dir }}", state: directory, mode: '0755' }

              - name: Minimal hardening | disable root SSH login
                lineinfile:
                  path: /etc/ssh/sshd_config
                  regexp: '^#?\s*PermitRootLogin\s+.*'
                  line: 'PermitRootLogin no'
                  backup: yes
                notify: restart sshd

              - name: Minimal hardening | ensure fail2ban (if available)
                package: { name: fail2ban, state: present }
                ignore_errors: yes

              - name: Ensure OpenSCAP content present (best effort)
                package: { name: scap-security-guide, state: present }
                ignore_errors: yes

              - name: Lynis | run audit
                command: >
                  lynis audit system --nocolors --quick
                  --logfile {{ reports_dir }}/lynis.log
                  --report-file {{ reports_dir }}/lynis-report.dat
                changed_when: false

              - name: OpenSCAP | locate SSG datastream
                shell: |
                  for p in /usr/share/xml/scap/ssg/ssg-al2023-ds.xml \
                           /usr/share/xml/scap/ssg/ssg-amazon_linux_2-ds.xml; do
                    test -f "$p" && { echo "$p"; exit 0; }
                  done
                  find /usr/share/xml/scap/ssg -maxdepth 1 -type f -name 'ssg-*-ds.xml' -print -quit
                register: ssg_ds
                changed_when: false
                failed_when: false

              - name: OpenSCAP | pick first profile (if content found)
                shell: oscap info {{ ssg_ds.stdout }} | awk '/^Profile/{print $2; exit}'
                register: prof
                changed_when: false
                failed_when: false
                when: ssg_ds.stdout | length > 0

              - name: OpenSCAP | eval -> results.xml + report.html
                command: >
                  oscap xccdf eval --fetch-remote-resources
                  --results {{ reports_dir }}/openscap-results.xml
                  --report  {{ reports_dir }}/openscap-report.html
                  {% if prof.stdout %} --profile {{ prof.stdout }} {% endif %}
                  {{ ssg_ds.stdout }}
                changed_when: false
                when: ssg_ds.stdout | length > 0

              - name: OpenSCAP | warn when no content
                debug:
                  msg: "No SSG datastream found; skipping OpenSCAP on this AMI."
                when: ssg_ds.stdout | length == 0

            handlers:
              - name: restart sshd
                service: { name: sshd, state: restarted }
          PYAML

          ansible-playbook -i "localhost," -c local --become /tmp/pb.yml

          cat >/tmp/summarize_json.py <<'PY'
          import json, os, re, sys
          from datetime import datetime, timezone
          def r(p):
            try: return open(p,encoding="utf-8",errors="ignore").read()
            except: return ""
          def idx(t):
            m=re.search(r'hardening[_ ]index[^0-9]*([0-9]{1,3})',t,re.I); return int(m.group(1)) if m else 0
          def score(x):
            m=re.search(r'score="([0-9]+(?:\.[0-9]+)?)"',x); return float(m.group(1)) if m else 0.0
          out=sys.argv[3]
          data={
            "timestamp_utc": datetime.now(timezone.utc).isoformat(),
            "hostname": os.uname().nodename,
            "instance_id": os.popen("curl -s http://169.254.169.254/latest/meta-data/instance-id").read().strip(),
            "region": os.environ.get("REGION",""),
            "bucket": os.environ.get("BUCKET",""),
            "run_id": os.environ.get("RUN",""),
            "lynis_hardening_index": idx(r(sys.argv[1])),
            "openscap_score": score(r(sys.argv[2])),
            "artifacts":{
              "lynis_log": "/tmp/reports/lynis.log",
              "lynis_report": "/tmp/reports/lynis-report.dat",
              "openscap_results": "/tmp/reports/openscap-results.xml",
              "openscap_html": "/tmp/reports/openscap-report.html"
            }
          }
          open(out,"w").write(json.dumps(data))
          print(json.dumps(data))
          PY

          python3 /tmp/summarize_json.py /tmp/reports/lynis-report.dat /tmp/reports/openscap-results.xml /tmp/reports/summary.json >/tmp/summary.stdout

          for f in lynis-report.dat lynis.log openscap-report.html openscap-results.xml summary.json; do
            [ -f "/tmp/reports/$f" ] && aws s3 cp "/tmp/reports/$f" "s3://$BUCKET/$RUN/${PHASE}/$f" --region "$REGION" || true
          done
          aws s3 sync "s3://$BUCKET/$RUN/" "s3://$BUCKET/latest/" --delete --region "$REGION" || true

          echo '---SUMMARY-JSON---'
          cat /tmp/reports/summary.json || cat /tmp/summary.stdout || true
          echo '---END-SUMMARY---'
          EOS
          chmod +x remote.sh

          KEY="ci-scripts/${RUN}/remote.sh"
          aws s3 cp remote.sh "s3://${BUCKET}/${KEY}" --region "${REGION}"
          echo "key=${KEY}" >> "$GITHUB_OUTPUT"

      - name: Send SSM command (download & execute remote script)
        id: ssm
        shell: bash
        env:
          RUN:    ${{ steps.stage.outputs.run }}
          KEY:    ${{ steps.stage.outputs.key }}
          BUCKET: ${{ env.BUCKET }}
          REGION: ${{ env.AWS_REGION }}
        run: |
          set -euo pipefail
          IID="${{ steps.target.outputs.iid }}"
          CMD_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "$IID" \
            --comment "Compliance scan $RUN" \
            --parameters commands="aws s3 cp s3://$BUCKET/$KEY /tmp/remote.sh --region $REGION && sudo bash /tmp/remote.sh" \
            --query "Command.CommandId" --output text)
          echo "cmd_id=$CMD_ID" >> "$GITHUB_OUTPUT"

          for _ in $(seq 1 60); do
            STATUS=$(aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$IID" --query Status --output text || true)
            [[ "$STATUS" =~ ^(Success|Failed|Cancelled|TimedOut)$ ]] && break
            sleep 5
          done
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$IID" --output json > out.json
          jq -r '.StandardOutputContent' out.json > stdout.txt
          awk '/---SUMMARY-JSON---/{flag=1;next}/---END-SUMMARY---/{flag=0}flag' stdout.txt > summary.json
          jq . summary.json || { echo "summary.json missing"; tail -n 200 stdout.txt || true; }

      - name: Emit CloudWatch metrics
        if: ${{ hashFiles('summary.json') != '' }}
        shell: bash
        run: |
          set -euo pipefail
          RUN="${{ steps.stage.outputs.run }}"
          IID="${{ steps.target.outputs.iid }}"
          LYNIS=$(jq -r '.lynis_hardening_index // 0' summary.json)
          OSCAP=$(jq -r '.openscap_score // 0' summary.json)
          STATUS=1
          aws cloudwatch put-metric-data --namespace "ComplianceMetrics" --metric-data "[
            {\"MetricName\":\"LynisHardeningIndex\",\"Value\":$LYNIS,\"Unit\":\"Count\",
             \"Dimensions\":[{\"Name\":\"InstanceId\",\"Value\":\"$IID\"},{\"Name\":\"Run\",\"Value\":\"$RUN\"}]},
            {\"MetricName\":\"OpenSCAPScore\",\"Value\":$OSCAP,\"Unit\":\"Percent\",
             \"Dimensions\":[{\"Name\":\"InstanceId\",\"Value\":\"$IID\"},{\"Name\":\"Run\",\"Value\":\"$RUN\"}]},
            {\"MetricName\":\"Status\",\"Value\":$STATUS,\"Unit\":\"Count\",
             \"Dimensions\":[{\"Name\":\"InstanceId\",\"Value\":\"$IID\"},{\"Name\":\"Run\",\"Value\":\"$RUN\"}]}
          ]"

      - name: Output links
        shell: bash
        run: |
          RUN="${{ steps.stage.outputs.run }}"
          echo "Run URL:    http://${{ env.BUCKET }}.s3-website-${{ env.AWS_REGION }}.amazonaws.com/$RUN/"
          echo "Latest URL: http://${{ env.BUCKET }}.s3-website-${{ env.AWS_REGION }}.amazonaws.com/latest/"
